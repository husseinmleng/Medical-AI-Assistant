import asyncio
import os
import sys
from datetime import datetime
from typing import List, Dict

# Add the project root to the Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.latex_agent import generate_latex_report
from src.tools import convert_latex_to_pdf


async def demo_translation_and_report_generation():
    """
    Complete demonstration of the Arabic-to-English translation and PDF report generation.
    """
    print("ğŸ©º Medical AI Assistant - Report Generation Demo")
    print("=" * 60)
    
    # Sample Arabic conversation (real medical consultation scenario)
    print("ğŸ“ Sample Arabic Medical Conversation:")
    arabic_conversation = [
        {
            "role": "assistant", 
            "content": "Ù…Ø±Ø­Ø¨Ù‹Ø§! Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø·Ø¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ. Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…ØŒ Ø³Ø£Ø­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø·Ø±Ø­ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø­ÙˆÙ„ ØªØ§Ø±ÙŠØ®Ùƒ Ø§Ù„ØµØ­ÙŠ. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ"
        },
        {
            "role": "user", 
            "content": "Ù…Ø±Ø­Ø¨Ø§ Ø¯ÙƒØªÙˆØ±ØŒ Ø£Ø´Ø¹Ø± Ø¨Ø£Ù„Ù… ÙÙŠ Ø§Ù„ØµØ¯Ø± Ù…Ù†Ø° Ø£Ø³Ø¨ÙˆØ¹ ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹ ÙˆØ£Ø´Ø¹Ø± Ø¨Ø§Ù„ØªØ¹Ø¨ Ø§Ù„Ø´Ø¯ÙŠØ¯"
        },
        {
            "role": "assistant", 
            "content": "Ø£ÙÙ‡Ù… Ù‚Ù„Ù‚Ùƒ. Ø¯Ø¹Ù†ÙŠ Ø£Ø³Ø£Ù„Ùƒ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ù‡Ù…Ø©. ÙƒÙ… Ø¹Ù…Ø±ÙƒØŸ"
        },
        {
            "role": "user", 
            "content": "Ø¹Ù…Ø±ÙŠ 35 Ø³Ù†Ø©"
        },
        {
            "role": "assistant", 
            "content": "Ø´ÙƒØ±Ø§Ù‹ Ù„Ùƒ. Ù‡Ù„ Ù„Ø¯ÙŠÙƒ ØªØ§Ø±ÙŠØ® Ø¹Ø§Ø¦Ù„ÙŠ Ø¨Ø³Ø±Ø·Ø§Ù† Ø§Ù„Ø«Ø¯ÙŠØŸ"
        },
        {
            "role": "user", 
            "content": "Ù†Ø¹Ù…ØŒ ÙˆØ§Ù„Ø¯ØªÙŠ Ø£ØµÙŠØ¨Øª Ø¨Ø³Ø±Ø·Ø§Ù† Ø§Ù„Ø«Ø¯ÙŠ Ù…Ù† Ù‚Ø¨Ù„"
        },
        {
            "role": "assistant", 
            "content": "Ù‡Ù„ Ù„Ø§Ø­Ø¸Øª ÙÙ‚Ø¯Ø§Ù† ÙˆØ²Ù† Ù…Ø¤Ø®Ø±Ø§Ù‹ Ø¯ÙˆÙ† Ø§ØªØ¨Ø§Ø¹ Ø­Ù…ÙŠØ©ØŸ"
        },
        {
            "role": "user", 
            "content": "Ù†Ø¹Ù…ØŒ ÙÙ‚Ø¯Øª Ø­ÙˆØ§Ù„ÙŠ 5 ÙƒÙŠÙ„Ùˆ ÙÙŠ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù…Ø§Ø¶ÙŠ"
        },
        {
            "role": "assistant", 
            "content": "Ù‡Ù„ Ø³Ø¨Ù‚ ÙˆØ£Ù† Ø¹Ø§Ù†ÙŠØª Ù…Ù† Ù…Ø´Ø§ÙƒÙ„ ÙÙŠ Ø§Ù„Ø«Ø¯ÙŠ Ù…Ù† Ù‚Ø¨Ù„ØŸ"
        },
        {
            "role": "user", 
            "content": "Ù„Ø§ØŒ Ù„Ù… Ø£Ø¹Ø§Ù†ÙŠ Ù…Ù† Ù…Ø´Ø§ÙƒÙ„ Ø³Ø§Ø¨Ù‚Ø©"
        },
        {
            "role": "assistant", 
            "content": "ÙƒÙ… ÙŠÙˆÙ…Ø§Ù‹ ØªØ¹Ø§Ù†ÙŠÙ† Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ØŸ"
        },
        {
            "role": "user", 
            "content": "Ø­ÙˆØ§Ù„ÙŠ 10 Ø£ÙŠØ§Ù…"
        },
        {
            "role": "assistant", 
            "content": "Ù‡Ù„ ØªØ´Ø¹Ø±ÙŠÙ† Ø¨Ø§Ù„ØªØ¹Ø¨ ÙˆØ§Ù„Ø¥Ø±Ù‡Ø§Ù‚ØŸ"
        },
        {
            "role": "user", 
            "content": "Ù†Ø¹Ù…ØŒ Ø£Ø´Ø¹Ø± Ø¨ØªØ¹Ø¨ Ø´Ø¯ÙŠØ¯ Ø­ØªÙ‰ Ù…Ø¹ Ø§Ù„Ø±Ø§Ø­Ø©"
        },
        {
            "role": "assistant", 
            "content": """Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒØŒ Ù‡Ù†Ø§Ùƒ Ø¨Ø¹Ø¶ Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„ØªÙŠ ØªØ³ØªØ¯Ø¹ÙŠ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡:

Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©
Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©: 85%

Ø§Ù„ØªÙØ³ÙŠØ±: Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ ØªØ¸Ù‡Ø± ÙˆØ¬ÙˆØ¯ Ø¹Ø¯Ø© Ø¹ÙˆØ§Ù…Ù„ Ø®Ø·Ø± Ù…Ø¬ØªÙ…Ø¹Ø© - Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¹Ø§Ø¦Ù„ÙŠ Ù„Ø³Ø±Ø·Ø§Ù† Ø§Ù„Ø«Ø¯ÙŠØŒ ÙÙ‚Ø¯Ø§Ù† Ø§Ù„ÙˆØ²Ù† ØºÙŠØ± Ø§Ù„Ù…Ø¨Ø±Ø±ØŒ ÙˆØ§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ù…Ø³ØªÙ…Ø±Ø© Ù„Ø£ÙƒØ«Ø± Ù…Ù† Ø£Ø³Ø¨ÙˆØ¹ Ù…Ø¹ Ø§Ù„ØªØ¹Ø¨. Ù‡Ø°Ø§ Ù„Ø§ ÙŠØ¹Ù†ÙŠ Ø¨Ø§Ù„Ø¶Ø±ÙˆØ±Ø© ÙˆØ¬ÙˆØ¯ Ù…Ø±Ø¶ØŒ Ù„ÙƒÙ†Ù‡ ÙŠØ³ØªØ¯Ø¹ÙŠ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ø·Ø¨ÙŠØ©.

Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø£Ù‡Ù… Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø§ØªØ®Ø§Ø°Ù‡Ø§ Ø§Ù„Ø¢Ù† Ù‡ÙŠ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø·Ø¨ÙŠØ¨ Ù…Ø®ØªØµ Ù„Ù…Ù†Ø§Ù‚Ø´Ø© Ù‡Ø°Ù‡ Ø§Ù„Ù†ØªØ§Ø¦Ø¬. Ù‡Ø°Ø§ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙ‚Ø· ÙˆÙ„ÙŠØ³ ØªØ´Ø®ÙŠØµØ§Ù‹ Ø·Ø¨ÙŠØ§Ù‹. Ø§Ù„Ø·Ø¨ÙŠØ¨ Ù‡Ùˆ Ø§Ù„ÙˆØ­ÙŠØ¯ Ø§Ù„Ù‚Ø§Ø¯Ø± Ø¹Ù„Ù‰ Ø¥Ø¹Ø·Ø§Ø¦Ùƒ Ø¥Ø¬Ø§Ø¨Ø© Ù†Ù‡Ø§Ø¦ÙŠØ© ÙˆØªÙˆØ¬ÙŠÙ‡Ùƒ Ù„Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©."""
        }
    ]
    
    for i, msg in enumerate(arabic_conversation[:4], 1):
        print(f"  {i}. {msg['role'].title()}: {msg['content'][:50]}...")
    print(f"  ... (total {len(arabic_conversation)} messages)")
    
    # Step 1: Translation
    print(f"\nğŸ”„ Step 1: Translating conversation from Arabic to English...")
    try:
        from src.app_logic import translate_conversation_to_english
        translated_conversation = await translate_conversation_to_english(arabic_conversation)
        print(f"âœ… Translation successful! {len(translated_conversation)} messages translated.")
        
        print("\nğŸ“– Sample translated messages:")
        for i, msg in enumerate(translated_conversation[:2], 1):
            print(f"  {i}. {msg['role'].title()}: {msg['content'][:80]}...")
            
    except Exception as e:
        print(f"âŒ Translation failed: {e}")
        print("ğŸ”„ Using original conversation for demo purposes...")
        translated_conversation = [
            {"role": "assistant", "content": "Hello! I'm your AI Medical Assistant. To start the assessment, I need to ask some questions about your health history. How can I help you today?"},
            {"role": "user", "content": "Hello doctor, I have chest pain for about a week and I feel very tired"},
            {"role": "assistant", "content": "I understand your concern. Let me ask some important questions. What is your age?"},
            {"role": "user", "content": "I am 35 years old"},
            {"role": "assistant", "content": "Thank you. Do you have a family history of breast cancer?"},
            {"role": "user", "content": "Yes, my mother had breast cancer before"},
            {"role": "assistant", "content": "Have you noticed recent weight loss without dieting?"},
            {"role": "user", "content": "Yes, I lost about 5 kg in the past month"},
            {"role": "assistant", "content": "Have you ever had breast problems before?"},
            {"role": "user", "content": "No, I haven't had previous problems"},
            {"role": "assistant", "content": "How many days have you been experiencing these symptoms?"},
            {"role": "user", "content": "About 10 days"},
            {"role": "assistant", "content": "Do you feel fatigue and exhaustion?"},
            {"role": "user", "content": "Yes, I feel severe fatigue even with rest"},
            {"role": "assistant", "content": """Based on your answers, there are some factors that require attention:

Result: Positive
Confidence: 85%

Explanation: Your answers show several risk factors combined - family history of breast cancer, unexplained weight loss, and persistent symptoms for more than a week with fatigue. This doesn't necessarily mean there's a disease, but it requires medical follow-up.

The most important step you should take now is to consult with a specialist doctor to discuss these results. This analysis is just a helpful tool and not a medical diagnosis. The doctor is the only one who can give you a definitive answer and guide you to the next step."""}
        ]
    
    # Step 2: Prepare sample data
    print(f"\nğŸ“‹ Step 2: Preparing patient and analysis data...")
    
    patient_info = {
        "patient_name": "Sarah Ahmed",
        "age": "35",
        "breast_feeding_months": "18",
        "family_history_breast_cancer": "yes",
        "recent_weight_loss": "yes", 
        "previous_breast_conditions": "no",
        "symptom_duration_days": "10",
        "fatigue": "yes"
    }
    
    analysis_results = {
        "ml_result": "Positive",
        "ml_confidence": 85.0,
        "xray_result": "Pending",
        "xray_confidence": None,
        "annotated_image_path": None,
        "interpretation_result": "Patient presents with multiple risk factors requiring immediate medical attention. Combination of family history, unexplained weight loss, and persistent symptoms warrants urgent consultation with oncology specialist.",
        "reports_text_context": None
    }
    
    print("âœ… Sample data prepared:")
    print(f"  - Patient: {patient_info['patient_name']}, Age: {patient_info['age']}")
    print(f"  - ML Assessment: {analysis_results['ml_result']} ({analysis_results['ml_confidence']}% confidence)")
    
    # Step 3: Generate LaTeX report
    print(f"\nğŸ“„ Step 3: Generating professional LaTeX report...")
    try:
        latex_content = generate_latex_report(
            conversation=translated_conversation,
            patient_info=patient_info,
            analysis_results=analysis_results,
            patient_name=patient_info["patient_name"],
            report_title="Medical AI Assistant - Breast Cancer Risk Assessment Report"
        )
        
        print("âœ… LaTeX report generated successfully!")
        print(f"  - Document length: {len(latex_content):,} characters")
        print(f"  - Sections included: Patient Info, Analysis Results, Key Findings, Conversation, Recommendations")
        
        # Save LaTeX source for inspection
        latex_filename = f"demo_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.tex"
        with open(latex_filename, 'w', encoding='utf-8') as f:
            f.write(latex_content)
        print(f"  - LaTeX source saved as: {latex_filename}")
        
    except Exception as e:
        print(f"âŒ LaTeX generation failed: {e}")
        return
    
    # Step 4: Convert to PDF
    print(f"\nğŸ”„ Step 4: Converting LaTeX to PDF...")
    try:
        pdf_filename = f"demo_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
        pdf_path = convert_latex_to_pdf(latex_content, pdf_filename)
        
        if pdf_path and "Error" not in pdf_path and os.path.exists(pdf_path):
            file_size = os.path.getsize(pdf_path) / 1024  # KB
            print("âœ… PDF report generated successfully!")
            print(f"  - PDF saved as: {pdf_path}")
            print(f"  - File size: {file_size:.1f} KB")
            
            # Verify PDF content
            print(f"\nğŸ“Š Report Statistics:")
            conversation_words = sum(len(msg['content'].split()) for msg in translated_conversation)
            print(f"  - Conversation: {len(translated_conversation)} messages, ~{conversation_words} words")
            print(f"  - Patient data fields: {len([k for k, v in patient_info.items() if v])}")
            print(f"  - Analysis results: {len([k for k, v in analysis_results.items() if v is not None])}")
            
        else:
            print(f"âŒ PDF generation failed: {pdf_path}")
            
    except Exception as e:
        print(f"âŒ PDF conversion failed: {e}")
        return
    
    # Step 5: Demo summary
    print(f"\nğŸ‰ Demo completed successfully!")
    print("=" * 60)
    print("ğŸ“‹ Summary of what was accomplished:")
    print("  1. âœ… Arabic medical conversation translated to English")
    print("  2. âœ… Professional LaTeX medical report generated")
    print("  3. âœ… PDF report compiled and saved")
    print("  4. âœ… Complete medical documentation workflow demonstrated")
    
    print(f"\nğŸ’¡ The generated report includes:")
    print("  - Professional medical report formatting")
    print("  - Patient information and questionnaire data")
    print("  - AI analysis results and confidence levels")
    print("  - Complete conversation transcript")
    print("  - Medical recommendations and disclaimers")
    print("  - Proper medical report structure and styling")
    
    if 'pdf_path' in locals() and os.path.exists(pdf_path):
        print(f"\nğŸ“ Files generated:")
        print(f"  - LaTeX source: {latex_filename}")
        print(f"  - PDF report: {pdf_path}")
        print(f"\nğŸ” You can now open the PDF to see the complete medical report!")


def demo_report_customization():
    """
    Demonstrate different report customization options.
    """
    print("\nğŸ¨ Report Customization Demo")
    print("-" * 40)
    
    # Different report styles
    styles = {
        "standard": "Standard Medical Report",
        "emergency": "Emergency Assessment Report", 
        "followup": "Follow-up Consultation Report",
        "screening": "Preventive Screening Report"
    }
    
    for style_key, style_name in styles.items():
        print(f"  ğŸ“‹ {style_name}")
        # In a real implementation, you would have different LaTeX templates
        print(f"     - Template: medical_{style_key}.tex")
        print(f"     - Styling: {style_key}_colors.sty")
        print(f"     - Sections: {style_key}_sections.json")


def demo_performance_testing():
    """
    Demonstrate performance characteristics of the report generation system.
    """
    print("\nâš¡ Performance Testing Demo")
    print("-" * 40)
    
    import time
    
    # Simulate different conversation lengths
    conversation_sizes = [
        ("Short", 5, "Quick consultation"),
        ("Medium", 15, "Standard consultation"),
        ("Long", 30, "Comprehensive assessment"),
        ("Extended", 50, "Multi-session consultation")
    ]
    
    for size_name, msg_count, description in conversation_sizes:
        print(f"  ğŸ“Š {size_name} Conversation ({msg_count} messages)")
        print(f"     Description: {description}")
        
        # Estimated timings based on typical performance
        estimated_translation = msg_count * 0.3  # ~300ms per message
        estimated_latex = 2.0  # Fixed LaTeX generation time
        estimated_pdf = 4.0    # Fixed PDF compilation time
        total_time = estimated_translation + estimated_latex + estimated_pdf
        
        print(f"     Est. Translation: {estimated_translation:.1f}s")
        print(f"     Est. LaTeX Gen: {estimated_latex:.1f}s") 
        print(f"     Est. PDF Comp: {estimated_pdf:.1f}s")
        print(f"     Total Time: {total_time:.1f}s")
        print()


if __name__ == "__main__":
    print("ğŸš€ Starting Medical AI Assistant Report Generation Demo")
    print("This demo will show the complete workflow from Arabic conversation to PDF report.\n")
    
    try:
        # Run the main demo
        asyncio.run(demo_translation_and_report_generation())
        
        # Additional demos
        demo_report_customization()
        demo_performance_testing()
        
        print("\nâœ¨ Demo completed successfully!")
        print("You can now integrate this system into your Medical AI Assistant.")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  Demo interrupted by user.")
    except Exception as e:
        print(f"\nâŒ Demo failed with error: {e}")
        import traceback
        traceback.print_exc()